			Frequent Itemset Mining 7/15/2015

0.0	Algorithm

This directory implements a shared-memory, STAPL-based version of the ECLAT
algorithm for computing Frequent Itemset Mining.

The original distributed-memory version is described in 
"A Localized Algorithm for Parallel Association Mining"
 by Zaki, Parthasarathy and Li.


1.0	Building Frequent Itemset Mining

cd ~/stapl/trunk/benchmarks/data_mining/frequent_itemset

make


2.0	Executing Frequent Itemset Mining

2.1	Command Line Arguments

Required arguments

argv[1] - input meta file name

argv[2] - input data file name

argv[3] - output file name

Optional arguments

argv[4] - 'b' (binary) or 't' text input
          The default is binary.

argv[5] - 'y' (run once) or 'n' (run for confidence levels)
          The default is run once.

argv[6] - Minimum Support Level 
          The range is [0.0,1.0]. The default is 0.05.
          If you aren't getting enough interesting frequent itemsets,
          in the result, then decrease this value.  
          If you are getting too many itemsets, in the result,
          the increase this value.  
          Legitimate values vary widely depending on the input data set.

argv[6] - Minimum Confidence 
          The range is [0.0,1.0]. The default is 0.9.

argv[7] - load balancing factor 
          The default is 1.5.  This was empirically determined,
          so you really need to know what you are doing if you change it.

Here is an example of executing the program

mpiexec -n 2 ./freqmine.exe sample.meta sample.txt sample.out t 0.05


2.2	Meta Data File

The meta data file is a binary file containing the following information
about a set of transactions:

1) transaction count (integer)
2) maximum transaction size (integer)
3) total unique items (integer)
4) unique item counts (array of integers)
5) item counts per transaction (array of integers)

Generate the meta data file by running the preprocessor:

./prep.exe infile metafile outfile

The infile must be a text file with one transaction per line.
Each transaction contains non-negative integer items separated by
at least one blank.

The metafile and outfile will be overwritten.


2.3	Output File

The output of Frequent Itemset Mining is a text file which contains
the frequent itemsets.  One itemset is contained on each line.
Items within the set are separated by colons.  The number of itemsets
generated depends on the Minimum Support Level and the Minimum Confidence Level.


3.0	Debugging Frequent Itemset Mining

3.1	Debug Output File

The name of the debug output file will be freqmine[N].dbg,
where N is an integer generated by calling time(NULL).

The following #defines can be activated within the source code.
The information described below will be written to the debug file.
Warning: some of the lower level output can be quite voluminous.


driver.cc: DBG_STEP 

Prints the values read by from the metadata file.
Prints the global values computed for key encoding.


freqmine.cc: DBG_ARB_DIST

Prints intermediate results in the computation of the arbitrary distribution.

freqmine.cc: DBG_EQUIV

Prints tracing information on which of the equivalence builders is used,
   intermediate results used in the computation,
   and the results of the equivalance class computation.


eclat1d.cc: DBG_STEP

Trace major steps of the ECLAT algorithm.

eclat1d.cc: DBG_PHASE

Trace sub-steps of the ECLAT algorithm.

eclat1d.cc: DBG_DATA

Dump the major data structures as they are produced:
1) the input data in horizontal format.
2) the 2-itemsets found in the input data.
3) the input data in vertical format


eclat1d_step2.cc: DBG_DATA 

Dump the data structures used to produce the 2-itemsets.


eclat1d_step3.cc: DBG_SRCH

Trace searches for pairs as vertical database is constructed.

eclat1d_step3.cc: DBG_DATA

Dump input intermediate data structures used in building vertical database.

eclat1d_step3.cc: DBG_VERT

Dump intermediate data structures constructed in building vertical database.

eclat1d_step3.cc: DBG_EQUIV

Show output of equivalence class construction.

eclat1d_step3.cc: DBG_DUMP

Dump low level details of building vertical database.


eclat1d_step4.cc: DBG_STEP

Trace major steps of the ECLAT algorithm.

eclat1d_step4.cc: DBG_STACK

Trace the operations performed on the stack which is used in the
asynchronous phase to mimic recursion.

eclat1d_step4.cc: DBG_ASYNCH 

Trace the operations of the asynchronous phase.

eclat1d_step4.cc: DBG_TRACE

Low level timing of steps in asychronous phase


4.0	Auxiliary Tools

4.1	Input Preprocessor

The preprocessor converts an ASCII input file into two binary files
one containing meta-data, and the other the actual values.

Build the preprocessor with this procedure:

g++ -O2 preprocess.exe -o prep.exe


4.2	Plausible Input Generator

Two generated data sets are widely used for FIM experiments:

Dataset      Minimum Support level
T10I4D100K   0.0005
T40I10D100K  0.01

These datasets were generated by using the IBM Quest data generator.
These names are interpreted as follows:

T10 - 10 x 1000 transactions
I4  -  4: average number of items per transaction
D100K - 100 x 1000 total number of items

4.2.1	IBM Quest Generator

This source code was downloaded from here:

http://sourceforge.net/projects/ibmquestdatagen/files/latest/download

Build the IBM Quest Generator with this procedure:

cd ~/stapl/trunk/benchmarks/data_mining/IBMquest

make

4.2.2	Plausability and Scalability

See the script gener.sh in this directory for a set of commands that
generate plausible input sets that should be useful for scalability studies.

Plausible input sets 
a) can have as many transactions as necessary to get scaling
   (i.e how many unique combinations of people/date visits resulting in 
    purchases occur in Walmarts nationwide in a month?)
a) have average transaction size < 100 
   (i.e. how many items do people buy from Walmart on an average visit?)
b) have total number of items < 10000
   (i.e. how many unique items does Walmart stock in a Supercenter?)

